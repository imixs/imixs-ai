
## Performance Issues

https://github.com/abetlen/llama-cpp-python/issues/982



# Docker Test

    docker run -v ./models:/models ghcr.io/ggerganov/llama.cpp:light -m /models/mistral-7b-instruct-v0.2.Q4_K_M.gguf -p "Wer ist der aktuelle Bundeskanzler von Deutschland?" -n 512


# Llama-cpp-pyhton

API: 
https://llama-cpp-python.readthedocs.io/en/latest/api-reference/


# Prompt Engineering 

https://www.promptingguide.ai/models/mistral-7b

https://community.aws/content/2dFNOnLVQRhyrOrMsloofnW0ckZ/how-to-prompt-mistral-ai-models-and-why

https://blog.cloudflare.com/workers-ai-update-hello-mistral-7b-de-de

https://www.promptingguide.ai/models/mixtral

https://docs.mistral.ai/guides/prompting-capabilities/